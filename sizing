NTS: I'm DUMB I think I did these all with IAF instead of DSF (!?!?)

python train.py --nr_resnet=3 --nr_filters=128 --init_batch_size=12 --batch_size=12 --n_ex=12
python train.py --nr_resnet=3 --nr_filters=128 --init_batch_size=12 --batch_size=12 --n_ex=12
python train.py --nr_resnet=3 --nr_filters=128 --init_batch_size=16 --batch_size=16 --n_ex=16 --attn_rep=6

-------------------------------------------
Y python train.py --init_batch_size=16 --batch_size=16 --n_ex=16 --attn_rep=6 --nr_filters=192 --nr_resnet=1 --n_flows=3
N python train.py --init_batch_size=16 --batch_size=16 --n_ex=16 --attn_rep=6 --nr_filters=192 --nr_resnet=3 --n_flows=2
N python train.py --init_batch_size=16 --batch_size=16 --n_ex=16 --attn_rep=8 --nr_filters=192 --nr_resnet=2 --n_flows=2

Y python train.py --init_batch_size=16 --batch_size=16 --n_ex=16 --attn_rep=6 --nr_filters=160 --nr_resnet=2 --n_flows=2
Y python train.py --init_batch_size=16 --batch_size=16 --n_ex=16 --attn_rep=6 --nr_filters=128 --nr_resnet=3 --n_flows=2
YY python train.py --init_batch_size=16 --batch_size=16 --n_ex=16 --attn_rep=6 --nr_filters=160 --nr_resnet=3 --n_flows=2
N python train.py --init_batch_size=16 --batch_size=16 --n_ex=16 --attn_rep=6 --nr_filters=160 --nr_resnet=4 --n_flows=2
N python train.py --init_batch_size=16 --batch_size=16 --n_ex=16 --attn_rep=8 --nr_filters=128 --nr_resnet=4 --n_flows=2
YYY python train.py --init_batch_size=16 --batch_size=16 --n_ex=16 --attn_rep=6 --nr_filters=128 --nr_resnet=4 --n_flows=2


N python train.py --init_batch_size=16 --batch_size=16 --n_ex=16 --attn_rep=6 --nr_filters=256 --nr_resnet=2 --n_flows=2
YYY python train.py --init_batch_size=16 --batch_size=16 --n_ex=16 --attn_rep=6 --nr_filters=192 --nr_resnet=2 --n_flows=2

YYY
python train.py --init_batch_size=16 --batch_size=16 --n_ex=16 --attn_rep=6 --nr_filters=128 --nr_resnet=4 --n_flows=2 --model=dk_DSF1 --n_flow_params=24
python train.py --init_batch_size=16 --batch_size=16 --n_ex=16 --attn_rep=6 --nr_filters=192 --nr_resnet=2 --n_flows=2 --model=dk_DSF1 --n_flow_params=24

GOAL: SOTA -- we need the most powerful model (that we can train with batch_size=16...)o

I would expect that memory use should grow:
    ~ linear in attn_rep
    ~ linear in n_flows
    ~ quadratic in nr_filters
        doesn't seem to be the case!!!!!
    ~ linear in nr_resnet
    ~ linear in batchsize


name = 
exp = 
save_dir = 
launch_str = "borgy submit --name " + name + "-- bash -c stdbuf -oL " + exp + " 1>>" + save_dir + "/stdout 2>>" + save_dir + "/stderr"

# '/mnt/AIDATA/home/david.krueger/dev/pixelsnail-public/train.py' --exp_dir='ARG' 1>>stdout 2>>stderr"


